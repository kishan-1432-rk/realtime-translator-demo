{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishan-1432-rk/realtime-translator-demo/blob/main/Deep_ASR_Demo_with_AI4Bharat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries:\n",
        "# pip install torch transformers datasets soundfile accelerate\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import io\n",
        "\n",
        "# --- 1. ASR Model Class ---\n",
        "# This class encapsulates the ASR logic for different Indian languages.\n",
        "class IndicASR:\n",
        "    def __init__(self, language=\"hi\"):\n",
        "        \"\"\"\n",
        "        Initializes the ASR model for a specific language.\n",
        "\n",
        "        Args:\n",
        "            language (str): The language code ('hi' for Hindi, 'ta' for Tamil, 'gu' for Gujarati).\n",
        "        \"\"\"\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "        self.language_map = {\n",
        "            'hi': 'ai4bharat/indic-whisper-v2-hi',\n",
        "            'ta': 'ai4bharat/indic-whisper-v2-ta',\n",
        "            'gu': 'ai4bharat/indic-whisper-v2-gu',\n",
        "        }\n",
        "\n",
        "        if language not in self.language_map:\n",
        "            raise ValueError(f\"Unsupported language: {language}. Please choose from {list(self.language_map.keys())}\")\n",
        "\n",
        "        self.model_id = self.language_map[language]\n",
        "        print(f\"Loading model for {language} from {self.model_id}...\")\n",
        "\n",
        "        # Load the pre-trained model and processor from Hugging Face.\n",
        "        # This handles tokenization and feature extraction.\n",
        "        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "            self.model_id,\n",
        "            torch_dtype=self.torch_dtype,\n",
        "            low_cpu_mem_usage=True,\n",
        "            use_safetensors=True\n",
        "        ).to(self.device)\n",
        "        self.processor = AutoProcessor.from_pretrained(self.model_id)\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        \"\"\"\n",
        "        Transcribes the speech from an audio file.\n",
        "\n",
        "        Args:\n",
        "            audio_path (str): Path to the audio file (e.g., WAV format).\n",
        "\n",
        "        Returns:\n",
        "            str: The transcribed text.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read the audio file\n",
        "            audio_data, sampling_rate = sf.read(audio_path, dtype='float32')\n",
        "\n",
        "            # Process the audio to get input features for the model\n",
        "            input_features = self.processor(\n",
        "                audio_data,\n",
        "                sampling_rate=sampling_rate,\n",
        "                return_tensors=\"pt\"\n",
        "            ).input_features.to(self.device, dtype=self.torch_dtype)\n",
        "\n",
        "            # Generate the transcription using the model's generate method\n",
        "            predicted_ids = self.model.generate(\n",
        "                input_features,\n",
        "                max_new_tokens=128\n",
        "            )\n",
        "\n",
        "            # Decode the predicted IDs to get the text transcript\n",
        "            transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "            return transcription\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "# --- 2. Example Usage ---\n",
        "# The following code demonstrates how to use the IndicASR class.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Note: To run this code, you need to replace these with paths to your local audio files.\n",
        "    # The audio files should be in the specified languages.\n",
        "    # Placeholder paths are used here for demonstration.\n",
        "    hindi_audio_path = \"path/to/your/hindi_audio.wav\"\n",
        "    tamil_audio_path = \"path/to/your/tamil_audio.wav\"\n",
        "    gujarati_audio_path = \"path/to/your/gujarati_audio.wav\"\n",
        "    english_audio_path = \"path/to/your/english_audio.wav\" # Using the Hindi model for English as a common scenario\n",
        "\n",
        "    # Create instances for different languages\n",
        "    try:\n",
        "        hindi_asr = IndicASR(language='hi')\n",
        "        tamil_asr = IndicASR(language='ta')\n",
        "        gujarati_asr = IndicASR(language='gu')\n",
        "\n",
        "        print(\"\\n--- Transcribing Hindi Audio ---\")\n",
        "        transcribed_hindi_text = hindi_asr.transcribe(hindi_audio_path)\n",
        "        print(f\"Transcription (Hindi): {transcribed_hindi_text}\")\n",
        "\n",
        "        print(\"\\n--- Transcribing Tamil Audio ---\")\n",
        "        transcribed_tamil_text = tamil_asr.transcribe(tamil_audio_path)\n",
        "        print(f\"Transcription (Tamil): {transcribed_tamil_text}\")\n",
        "\n",
        "        print(\"\\n--- Transcribing Gujarati Audio ---\")\n",
        "        transcribed_gujarati_text = gujarati_asr.transcribe(gujarati_audio_path)\n",
        "        print(f\"Transcription (Gujarati): {transcribed_gujarati_text}\")\n",
        "\n",
        "        # You can also use one of the models for English, as many are trained on English as well.\n",
        "        print(\"\\n--- Transcribing English Audio with Hindi Model ---\")\n",
        "        transcribed_english_text = hindi_asr.transcribe(english_audio_path)\n",
        "        print(f\"Transcription (English): {transcribed_english_text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during initialization or transcription: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model for hi from ai4bharat/indic-whisper-v2-hi...\n",
            "An error occurred during initialization or transcription: ai4bharat/indic-whisper-v2-hi is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXISObeYPw8T",
        "outputId": "d247e2f6-8a65-4eb9-d29d-576233a9491f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvNAsHj3Pxog"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}